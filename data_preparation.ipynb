{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe3b2f10",
   "metadata": {},
   "source": [
    "## Step 1: Load and Combine Individual Company CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fe4e9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 2.3.3\n",
      "NumPy: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78742e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 company files\n",
      "Companies: ['ADBL', 'CZBIL', 'EBL', 'GBIME', 'HBL', 'KBL', 'MBL', 'NABIL', 'NBL', 'NICA', 'NMB', 'PCBL', 'PRVU', 'SANIMA', 'SBI', 'SBL', 'SCB']\n"
     ]
    }
   ],
   "source": [
    "# Load all company CSV files\n",
    "DATA_DIR = \"commercial-banks/\"\n",
    "csv_files = glob.glob(os.path.join(DATA_DIR, \"*.csv\"))\n",
    "\n",
    "print(f\"Found {len(csv_files)} company files\")\n",
    "print(f\"Companies: {sorted([os.path.basename(f).split('.')[0] for f in csv_files])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bba70371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SCB: 3342 rows\n",
      "Loaded NICA: 2842 rows\n",
      "Loaded PCBL: 3342 rows\n",
      "Loaded PRVU: 2192 rows\n",
      "Loaded EBL: 3342 rows\n",
      "Loaded GBIME: 2598 rows\n",
      "Loaded CZBIL: 3742 rows\n",
      "Loaded KBL: 3150 rows\n",
      "Loaded MBL: 2992 rows\n",
      "Loaded HBL: 3077 rows\n",
      "Loaded SBL: 3192 rows\n",
      "Loaded SANIMA: 3142 rows\n",
      "Loaded NABIL: 3342 rows\n",
      "Loaded ADBL: 3492 rows\n",
      "Loaded SBI: 3342 rows\n",
      "Loaded NBL: 2942 rows\n",
      "Loaded NMB: 2992 rows\n",
      "\n",
      "Combined dataset: (53063, 10)\n"
     ]
    }
   ],
   "source": [
    "# Combine all files into one dataframe\n",
    "df_list = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    company_id = os.path.basename(file).split('.')[0]\n",
    "    df['company_id'] = company_id\n",
    "    df_list.append(df)\n",
    "    print(f\"Loaded {company_id}: {df.shape[0]} rows\")\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "print(f\"\\nCombined dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fb9ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2009-06-25 00:00:00 to 2025-12-29 00:00:00\n",
      "Companies: 17\n",
      "\n",
      "Missing values:\n",
      "published_date     0\n",
      "open               0\n",
      "high               0\n",
      "low                0\n",
      "close              0\n",
      "per_change         0\n",
      "traded_quantity    0\n",
      "traded_amount      0\n",
      "company_id         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initial preprocessing\n",
    "df['published_date'] = pd.to_datetime(df['published_date'])\n",
    "df = df.sort_values(['company_id', 'published_date']).reset_index(drop=True)\n",
    "\n",
    "# Drop status column if exists\n",
    "if 'status' in df.columns:\n",
    "    df = df.drop(columns=['status'])\n",
    "\n",
    "# Recalculate per_change if missing\n",
    "df['per_change'] = df['per_change'].fillna(\n",
    "    ((df['close'] - df['open']) / df['open']) * 100\n",
    ")\n",
    "\n",
    "print(f\"Date range: {df['published_date'].min()} to {df['published_date'].max()}\")\n",
    "print(f\"Companies: {df['company_id'].nunique()}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ce9fe7",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Basic Features (Without Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb5d817b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic features per company...\n",
      "Shape after basic features: (53063, 12)\n"
     ]
    }
   ],
   "source": [
    "# Calculate basic features per company\n",
    "def add_basic_features(group):\n",
    "    group = group.copy()\n",
    "    \n",
    "    # Daily range\n",
    "    group['daily_range'] = group['high'] - group['low']\n",
    "    \n",
    "    # Moving averages (5-day and 20-day)\n",
    "    group['ma_5'] = group['close'].rolling(5).mean()\n",
    "    group['ma_20'] = group['close'].rolling(20).mean()\n",
    "    \n",
    "    return group\n",
    "\n",
    "print(\"Calculating basic features per company...\")\n",
    "df = df.groupby('company_id', group_keys=False).apply(add_basic_features)\n",
    "print(f\"Shape after basic features: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33adac79",
   "metadata": {},
   "source": [
    "## Step 3: Calculate Technical Indicators (Without Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce3741ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical indicator functions defined\n"
     ]
    }
   ],
   "source": [
    "# Technical indicator functions\n",
    "def calculate_rsi(prices, period=14):\n",
    "    \"\"\"Relative Strength Index\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26):\n",
    "    \"\"\"MACD (Moving Average Convergence Divergence)\"\"\"\n",
    "    ema_fast = prices.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = prices.ewm(span=slow, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    return macd\n",
    "\n",
    "def calculate_bollinger_position(prices, period=20, std_dev=2):\n",
    "    \"\"\"Position within Bollinger Bands (0 to 1)\"\"\"\n",
    "    sma = prices.rolling(window=period).mean()\n",
    "    std = prices.rolling(window=period).std()\n",
    "    upper_band = sma + (std * std_dev)\n",
    "    lower_band = sma - (std * std_dev)\n",
    "    bb_position = (prices - lower_band) / (upper_band - lower_band)\n",
    "    return bb_position\n",
    "\n",
    "def calculate_atr(high, low, close, period=14):\n",
    "    \"\"\"Average True Range (normalized)\"\"\"\n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - close.shift())\n",
    "    tr3 = abs(low - close.shift())\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    atr = tr.rolling(window=period).mean()\n",
    "    atr_normalized = atr / close\n",
    "    return atr_normalized\n",
    "\n",
    "print(\"Technical indicator functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0148d19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying technical indicators per company...\n",
      "Shape after technical indicators: (53063, 20)\n",
      "\n",
      "New columns: ['published_date', 'open', 'high', 'low', 'close', 'per_change', 'traded_quantity', 'traded_amount', 'company_id', 'daily_range', 'ma_5', 'ma_20', 'rsi_14', 'macd', 'bb_position', 'atr_normalized', 'volume_ratio', 'return_5d', 'price_to_ma20', 'trend_strength']\n"
     ]
    }
   ],
   "source": [
    "# Apply technical indicators per company\n",
    "def add_technical_indicators(group):\n",
    "    \"\"\"Add technical indicators for a single company\"\"\"\n",
    "    group = group.copy()\n",
    "    \n",
    "    # 1. RSI (14-day)\n",
    "    group['rsi_14'] = calculate_rsi(group['close'], 14)\n",
    "    \n",
    "    # 2. MACD\n",
    "    group['macd'] = calculate_macd(group['close'])\n",
    "    \n",
    "    # 3. Bollinger Band Position\n",
    "    group['bb_position'] = calculate_bollinger_position(group['close'])\n",
    "    \n",
    "    # 4. ATR Normalized\n",
    "    group['atr_normalized'] = calculate_atr(group['high'], group['low'], group['close'], 14)\n",
    "    \n",
    "    # 5. Volume Ratio\n",
    "    group['volume_ma_5'] = group['traded_quantity'].rolling(5).mean()\n",
    "    group['volume_ratio'] = group['traded_quantity'] / group['volume_ma_5']\n",
    "    \n",
    "    # 6. Return 5-day\n",
    "    group['return_5d'] = group['close'].pct_change(5)\n",
    "    \n",
    "    # 7. Price to MA20\n",
    "    group['price_to_ma20'] = group['close'] / group['ma_20']\n",
    "    \n",
    "    # 8. Trend Strength\n",
    "    group['ma_60'] = group['close'].rolling(60).mean()\n",
    "    group['trend_strength'] = (group['close'] - group['ma_60']) / group['ma_60']\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    group = group.drop(['volume_ma_5', 'ma_60'], axis=1, errors='ignore')\n",
    "    \n",
    "    return group\n",
    "\n",
    "print(\"Applying technical indicators per company...\")\n",
    "df = df.groupby('company_id', group_keys=False).apply(add_technical_indicators)\n",
    "print(f\"Shape after technical indicators: {df.shape}\")\n",
    "print(f\"\\nNew columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0597f1",
   "metadata": {},
   "source": [
    "## Step 4: Create Target Variable (Next-Day Movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73f7faf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating target variable...\n",
      "\n",
      "Target variable created\n",
      "\n",
      "Target distribution:\n",
      "  DOWN (0): 30,551 (57.6%)\n",
      "  UP (1): 22,512 (42.4%)\n",
      "  Balance ratio: 1.36:1\n"
     ]
    }
   ],
   "source": [
    "# Create target: predict tomorrow's direction based on today's close\n",
    "\n",
    "def add_target(group):\n",
    "    group = group.copy()\n",
    "    # Calculate next day's percentage change\n",
    "    group['pct_change_next'] = group['close'].pct_change().shift(-1) * 100\n",
    "    # Binary target: 1 if price goes UP tomorrow, 0 if DOWN\n",
    "    group['target'] = (group['pct_change_next'] > 0).astype(int)\n",
    "    return group\n",
    "\n",
    "print(\"Creating target variable...\")\n",
    "df = df.groupby('company_id', group_keys=False).apply(add_target)\n",
    "\n",
    "print(\"\\nTarget variable created\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "target_counts = df['target'].value_counts()\n",
    "target_pct = df['target'].value_counts(normalize=True) * 100\n",
    "print(f\"  DOWN (0): {target_counts[0]:,} ({target_pct[0]:.1f}%)\")\n",
    "print(f\"  UP (1): {target_counts[1]:,} ({target_pct[1]:.1f}%)\")\n",
    "balance = target_pct[0] / target_pct[1]\n",
    "print(f\"  Balance ratio: {balance:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37473580",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Temporal Alignment to verify no data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7bb30b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEMPORAL ALIGNMENT VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Sample data for NABIL:\n",
      "\n",
      "Row | Date       | Close  | RSI   | MA_5  | Target | Next_Day_Change\n",
      "----------------------------------------------------------------------\n",
      "22453 | 2011-08-16 | 1225.0 |  35.6 | 1217.2 | UP     |  +0.49%\n",
      "22454 | 2011-08-17 | 1231.0 |  39.9 | 1227.0 | DOWN   |  -0.57%\n",
      "22455 | 2011-08-18 | 1224.0 |  42.9 | 1225.0 | DOWN   |  -1.06%\n",
      "22456 | 2011-08-22 | 1211.0 |  34.8 | 1223.2 | DOWN   |  -0.91%\n",
      "22457 | 2011-08-23 | 1200.0 |  34.1 | 1218.2 | DOWN   |  -0.83%\n",
      "\n",
      "For row with Date = Day i:\n",
      "  - Close, RSI, MA_5 = Calculated using data UP TO Day i\n",
      "  - RSI uses rolling window (Days i-13 to i)\n",
      "  - MA_5 uses rolling window (Days i-4 to i)\n",
      "  - Target = Will Day i+1 be higher than Day i? (UP or DOWN)\n",
      "  - Next_Day_Change = Actual % change from Day i to Day i+1\n",
      "\n",
      "EXAMPLE:\n",
      "  Row with Date = 2020-01-05, Close = 100\n",
      "  - RSI/MA use prices from 2019-12-20 to 2020-01-05\n",
      "  - Target predicts: Will 2020-01-06 close > 100?\n",
      "  - This is 1-day ahead prediction using today's data\n",
      "\n",
      "✓ NO DATA LEAKAGE: Features use rolling windows (past + today)\n",
      "✓ Target predicts tomorrow based on today's close\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Detailed temporal alignment verification\n",
    "print(\"=\"*70)\n",
    "print(\"TEMPORAL ALIGNMENT VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get sample data for visualization\n",
    "test_company = 'NABIL'\n",
    "sample = df[df['company_id'] == test_company].iloc[60:65].copy()\n",
    "\n",
    "# Show actual prices and calculated values\n",
    "print(f\"\\nSample data for {test_company}:\")\n",
    "print(\"\\nRow | Date       | Close  | RSI   | MA_5  | Target | Next_Day_Change\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    date = row['published_date']\n",
    "    close = row['close']\n",
    "    rsi = row['rsi_14']\n",
    "    ma5 = row['ma_5']\n",
    "    target = row['target']\n",
    "    pct_next = row['pct_change_next']\n",
    "    \n",
    "    target_str = \"UP\" if target == 1 else \"DOWN\"\n",
    "    print(f\"{idx:3d} | {date.date()} | {close:6.1f} | {rsi:5.1f} | {ma5:6.1f} | {target_str:4s}   | {pct_next:+6.2f}%\")\n",
    "\n",
    "\n",
    "print(\"\\nFor row with Date = Day i:\")\n",
    "print(\"  - Close, RSI, MA_5 = Calculated using data UP TO Day i\")\n",
    "print(\"  - RSI uses rolling window (Days i-13 to i)\")\n",
    "print(\"  - MA_5 uses rolling window (Days i-4 to i)\")\n",
    "print(\"  - Target = Will Day i+1 be higher than Day i? (UP or DOWN)\")\n",
    "print(\"  - Next_Day_Change = Actual % change from Day i to Day i+1\")\n",
    "print(\"\\nEXAMPLE:\")\n",
    "print(\"  Row with Date = 2020-01-05, Close = 100\")\n",
    "print(\"  - RSI/MA use prices from 2019-12-20 to 2020-01-05\")\n",
    "print(\"  - Target predicts: Will 2020-01-06 close > 100?\")\n",
    "print(\"  - This is 1-day ahead prediction using today's data\")\n",
    "print(\"\\n✓ NO DATA LEAKAGE: Features use rolling windows (past + today)\")\n",
    "print(\"✓ Target predicts tomorrow based on today's close\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c20d7f",
   "metadata": {},
   "source": [
    "## Step 6: Clean and Verify Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "107c4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after feature engineering:\n",
      "ma_5                 68\n",
      "ma_20               323\n",
      "rsi_14              221\n",
      "bb_position         323\n",
      "atr_normalized      221\n",
      "volume_ratio         68\n",
      "return_5d            85\n",
      "price_to_ma20       323\n",
      "trend_strength     1003\n",
      "pct_change_next      17\n",
      "dtype: int64\n",
      "\n",
      "Dropped 1,020 rows with NaN\n",
      "Remaining rows: 52,043\n",
      "No missing values remaining\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values after feature engineering:\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "# Drop rows with NaN\n",
    "rows_before = len(df)\n",
    "df = df.dropna()\n",
    "print(f\"\\nDropped {rows_before - len(df):,} rows with NaN\")\n",
    "print(f\"Remaining rows: {len(df):,}\")\n",
    "\n",
    "# Verify no missing values\n",
    "assert df.isnull().sum().sum() == 0, \"Still have NaN values!\"\n",
    "print(\"No missing values remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af03944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA QUALITY VERIFICATION\n",
      "======================================================================\n",
      "No infinite values found\n",
      "\n",
      "Temporal Alignment Verification (NABIL):\n",
      "      published_date  close   ma_5     rsi_14  target  pct_change_next\n",
      "22512     2011-12-04  857.0  869.2  40.350877       0        -0.816803\n",
      "22513     2011-12-05  850.0  867.2  41.071429       0         0.000000\n",
      "22514     2011-12-06  850.0  859.8  43.670886       0        -0.823529\n",
      "22515     2011-12-07  843.0  854.0  42.592593       0        -0.355872\n",
      "22516     2011-12-08  840.0  848.0  38.853503       0        -2.023810\n",
      "  Row with date = Day i:\n",
      "    - close, ma_5, rsi_14 = values from Day i-1 (YESTERDAY)\n",
      "    - target = 1 if price goes UP from Day i to Day i+1 (TODAY to TOMORROW)\n",
      "    - pct_change_next = actual % change from Day i to Day i+1\n",
      "\n",
      "Example: Using YESTERDAY's indicators to predict TOMORROW's direction\n",
      "This is the correct temporal alignment - NO data leakage!\n"
     ]
    }
   ],
   "source": [
    "# Verify data quality\n",
    "print(\"=\"*70)\n",
    "print(\"DATA QUALITY VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for infinite values\n",
    "inf_check = np.isinf(df.select_dtypes(include=[np.number])).sum()\n",
    "if inf_check.sum() > 0:\n",
    "    print(\"\\nInfinite values found:\")\n",
    "    print(inf_check[inf_check > 0])\n",
    "    # Replace inf with NaN and drop\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.dropna()\n",
    "    print(f\"Cleaned infinite values, remaining rows: {len(df):,}\")\n",
    "else:\n",
    "    print(\"No infinite values found\")\n",
    "\n",
    "# Verify temporal alignment with detailed example\n",
    "print(\"\\nTemporal Alignment Verification (NABIL):\")\n",
    "sample = df[df['company_id'] == 'NABIL'].iloc[60:65][['published_date', 'close', 'ma_5', 'rsi_14', 'target', 'pct_change_next']]\n",
    "print(sample)\n",
    "print(\"  Row with date = Day i:\")\n",
    "print(\"    - close, ma_5, rsi_14 = values from Day i-1 (YESTERDAY)\")\n",
    "print(\"    - target = 1 if price goes UP from Day i to Day i+1 (TODAY to TOMORROW)\")\n",
    "print(\"    - pct_change_next = actual % change from Day i to Day i+1\")\n",
    "print(\"\\nExample: Using YESTERDAY's indicators to predict TOMORROW's direction\")\n",
    "print(\"This is the correct temporal alignment - NO data leakage!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c84d44",
   "metadata": {},
   "source": [
    "## Step 7: Final Summary and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd54e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL DATASET SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Shape: (52043, 22)\n",
      "Date range: 2009-09-27 00:00:00 to 2025-12-28 00:00:00\n",
      "Companies: 17\n",
      "\n",
      "Features:\n",
      "  - 10 Original features (OHLC, volume, moving averages) - ALL SHIFTED\n",
      "  - 8 Technical indicators (RSI, MACD, etc.) - ALL SHIFTED\n",
      "  - Total: 18 features\n",
      "\n",
      "Target:\n",
      "  - DOWN (0): 57.6%\n",
      "  - UP (1): 42.4%\n",
      "\n",
      "Critical Implementation:\n",
      "  - ALL features shifted by 1 day\n",
      "  - Predicting day i+1 using data from day i-1\n",
      "  - NO data leakage\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Select final columns\n",
    "final_columns = [\n",
    "    'published_date', 'company_id', 'target', 'pct_change_next',\n",
    "    # Original features (shifted)\n",
    "    'open', 'high', 'low', 'close', 'per_change',\n",
    "    'traded_quantity', 'traded_amount', 'daily_range',\n",
    "    # Moving averages (shifted)\n",
    "    'ma_5', 'ma_20',\n",
    "    # Technical indicators (shifted)\n",
    "    'rsi_14', 'macd', 'bb_position', 'atr_normalized',\n",
    "    'volume_ratio', 'return_5d', 'price_to_ma20', 'trend_strength'\n",
    "]\n",
    "\n",
    "final_df = df[final_columns].copy()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nShape: {final_df.shape}\")\n",
    "print(f\"Date range: {final_df['published_date'].min()} to {final_df['published_date'].max()}\")\n",
    "print(f\"Companies: {final_df['company_id'].nunique()}\")\n",
    "print(f\"\\nFeatures:\")\n",
    "print(f\"  - 10 Original features (OHLC, volume, moving averages) - ALL SHIFTED\")\n",
    "print(f\"  - 8 Technical indicators (RSI, MACD, etc.) - ALL SHIFTED\")\n",
    "print(f\"  - Total: 18 features\")\n",
    "print(f\"\\nTarget:\")\n",
    "target_dist = final_df['target'].value_counts(normalize=True) * 100\n",
    "print(f\"  - DOWN (0): {target_dist[0]:.1f}%\")\n",
    "print(f\"  - UP (1): {target_dist[1]:.1f}%\")\n",
    "print(f\"\\nCritical Implementation:\")\n",
    "print(f\"  - ALL features shifted by 1 day\")\n",
    "print(f\"  - Predicting day i+1 using data from day i-1\")\n",
    "print(f\"  - NO data leakage\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1efa3887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data exported to: stock_data_prepared_for_training.csv\n",
      "File size: 13.00 MB\n",
      "\n",
      "Ready for model training!\n"
     ]
    }
   ],
   "source": [
    "# Export to CSV\n",
    "output_file = 'stock_data_prepared_for_training.csv'\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nData exported to: {output_file}\")\n",
    "print(f\"File size: {os.path.getsize(output_file) / (1024*1024):.2f} MB\")\n",
    "print(\"\\nReady for model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec83178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification:\n",
      "  - Rows: 52,043\n",
      "  - Columns: 22\n",
      "  - Companies: 17\n",
      "  - No missing values: True\n",
      "\n",
      "Export successful!\n"
     ]
    }
   ],
   "source": [
    "# Quick verification of exported file\n",
    "verify_df = pd.read_csv(output_file)\n",
    "print(f\"Verification:\")\n",
    "print(f\"  - Rows: {len(verify_df):,}\")\n",
    "print(f\"  - Columns: {len(verify_df.columns)}\")\n",
    "print(f\"  - Companies: {verify_df['company_id'].nunique()}\")\n",
    "print(f\"  - No missing values: {verify_df.isnull().sum().sum() == 0}\")\n",
    "print(f\"\\nExport successful!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
